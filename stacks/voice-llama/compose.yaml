services:
  voice-llama:
    image: ghcr.io/bmv234/voice-llama:latest
    restart: unless-stopped
    ports:
      - "8443:8443"
    environment:
      - PYTHONUNBUFFERED=1
    extra_hosts:
      - "host.docker.internal:host-gateway"
    labels:
      - "dockge.description=Voice-enabled LLaMA chat interface"
      - "dockge.icon=message-circle"
      - "dockge.note=GPU-accelerated voice chat service"
